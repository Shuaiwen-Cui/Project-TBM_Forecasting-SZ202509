#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TBM APIæ•°æ®è·å–æ¨¡å— - å¢å¼ºé²æ£’æ€§ç‰ˆæœ¬ (api_client_robust.py)
========================================================

æ¨¡å—åŠŸèƒ½:
- ä»ç›¾æ„æœºAPIæ¥å£è·å–å®æ—¶æ•°æ®
- è§£æAPIè¿”å›çš„JSONæ•°æ®
- æå–31ä¸ªç‰¹å¾å¯¹åº”çš„ä¼ è¾“åæ•°æ®
- å¤„ç†æ•°æ®ç¼ºå¤±å’Œå¼‚å¸¸æƒ…å†µ
- å¢å¼ºçš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

æ¨¡å—èŒè´£:
- å°è£…APIè°ƒç”¨ç›¸å…³æ“ä½œ
- æä¾›ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£
- å¤„ç†æ•°æ®è§£æå’Œè½¬æ¢
- æä¾›é²æ£’çš„é”™è¯¯æ¢å¤æœºåˆ¶
"""

import requests
import json
import numpy as np
from datetime import datetime, timedelta
import time
import warnings
import logging
from typing import Optional, Dict, List, Tuple, Any
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# =============================================================================
# APIé…ç½®
# =============================================================================
class APIConfig:
    """APIé…ç½®ç±» - å¢å¼ºç‰ˆ"""
    BASE_URL = "https://szqhx.sinoccdc.com/qhx/shield/data/list"
    ACCESS_TOKEN = "0c46137497ffdf0369037ada468fe2d3"
    TBM_ID = "THDG24493"
    TIMEOUT = 30  # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
    MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
    RETRY_DELAY = 1  # é‡è¯•å»¶è¿Ÿ(ç§’)
    CONNECTION_TIMEOUT = 10  # è¿æ¥è¶…æ—¶(ç§’)
    READ_TIMEOUT = 30  # è¯»å–è¶…æ—¶(ç§’)
    REQUEST_INTERVAL = 1  # è¯·æ±‚é—´éš”(ç§’)
    
    # ç‰¹å¾ååˆ°ä¼ è¾“åçš„æ˜ å°„ï¼ˆå·²ä¿®æ­£ï¼Œæ‰€æœ‰31ä¸ªç‰¹å¾éƒ½æœ‰å¯¹åº”ä¼ è¾“åï¼‰
    FEATURE_MAPPING = {
        'è´¯å…¥åº¦': 'date120',
        'æ¨è¿›åŒºé—´çš„å‹åŠ›ï¼ˆä¸Šï¼‰': 'date16',
        'æ¨è¿›åŒºé—´çš„å‹åŠ›ï¼ˆå³ï¼‰': 'date17',
        'æ¨è¿›åŒºé—´çš„å‹åŠ›ï¼ˆä¸‹ï¼‰': 'date18',
        'æ¨è¿›åŒºé—´çš„å‹åŠ›ï¼ˆå·¦ï¼‰': 'date19',
        'åœŸèˆ±åœŸå‹ï¼ˆå³ï¼‰': 'date29',
        'åœŸèˆ±åœŸå‹ï¼ˆå³ä¸‹ï¼‰': 'date30',
        'åœŸèˆ±åœŸå‹ï¼ˆå·¦ï¼‰': 'date31',
        'åœŸèˆ±åœŸå‹ï¼ˆå·¦ä¸‹ï¼‰': 'date32',
        'No.16æ¨è¿›åƒæ–¤é¡¶é€Ÿåº¦': 'date7',
        'No.4æ¨è¿›åƒæ–¤é¡¶é€Ÿåº¦': 'date8',
        'No.8æ¨è¿›åƒæ–¤é¡¶é€Ÿåº¦': 'date9',
        'No.12æ¨è¿›åƒæ–¤é¡¶é€Ÿåº¦': 'date10',
        'æ¨è¿›æ²¹ç¼¸æ€»æ¨åŠ›': 'date11',
        'No.16æ¨è¿›åƒæ–¤é¡¶è¡Œç¨‹': 'date12',
        'No.4æ¨è¿›åƒæ–¤é¡¶è¡Œç¨‹': 'date13',
        'No.8æ¨è¿›åƒæ–¤é¡¶è¡Œç¨‹': 'date14',
        'No.12æ¨è¿›åƒæ–¤é¡¶è¡Œç¨‹': 'date15',
        'æ¨è¿›å¹³å‡é€Ÿåº¦': 'date20',
        'åˆ€ç›˜è½¬é€Ÿ': 'date21',
        'åˆ€ç›˜æ‰­çŸ©': 'date22',
        'No.1åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date23',
        'No.2åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date24',
        'No.3åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date25',
        'No.4åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date26',
        'No.5åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date27',
        'No.6åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date28',
        'No.7åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date29',
        'No.8åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date30',
        'No.9åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date31',
        'No.10åˆ€ç›˜ç”µæœºæ‰­çŸ©': 'date32'
    }

# =============================================================================
# TBM APIå®¢æˆ·ç«¯ - å¢å¼ºé²æ£’æ€§ç‰ˆæœ¬
# =============================================================================
class TBMAPIClientRobust:
    """
    TBM APIå®¢æˆ·ç«¯ - å¢å¼ºé²æ£’æ€§ç‰ˆæœ¬
    
    èŒè´£:
    1. è°ƒç”¨ç›¾æ„æœºæ•°æ®APIæ¥å£
    2. è§£æAPIè¿”å›çš„JSONæ•°æ®
    3. æå–31ä¸ªç‰¹å¾å¯¹åº”çš„æ•°æ®
    4. å¤„ç†APIè°ƒç”¨å¼‚å¸¸å’Œé”™è¯¯
    5. æä¾›é‡è¯•æœºåˆ¶å’Œé”™è¯¯æ¢å¤
    """
    
    def __init__(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        self.session = requests.Session()
        self.config = APIConfig()
        self.last_request_time = 0
        self.request_count = 0
        self.success_count = 0
        self.error_count = 0
        
        # è®¾ç½®ä¼šè¯é…ç½®
        self.session.headers.update({
            'User-Agent': 'TBM-Forecasting-System/1.0',
            'Accept': 'application/json',
            'Content-Type': 'application/json'
        })
        
        logger.info("TBM APIå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    def _rate_limit(self):
        """æ§åˆ¶è¯·æ±‚é¢‘ç‡"""
        current_time = time.time()
        if current_time - self.last_request_time < self.config.REQUEST_INTERVAL:
            sleep_time = self.config.REQUEST_INTERVAL - (current_time - self.last_request_time)
            logger.debug(f"è¯·æ±‚é¢‘ç‡æ§åˆ¶ï¼Œç­‰å¾… {sleep_time:.2f} ç§’")
            time.sleep(sleep_time)
    
    def _make_request(self, payload: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        å‘é€APIè¯·æ±‚ - å¸¦é‡è¯•æœºåˆ¶
        
        Args:
            payload: è¯·æ±‚è½½è·
            
        Returns:
            APIå“åº”æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        for attempt in range(self.config.MAX_RETRIES):
            try:
                self._rate_limit()
                
                # æ„å»ºè¯·æ±‚å‚æ•°
                params = {"access-token": self.config.ACCESS_TOKEN}
                
                # å‘é€è¯·æ±‚
                response = self.session.post(
                    self.config.BASE_URL,
                    params=params,
                    json=payload,
                    timeout=(self.config.CONNECTION_TIMEOUT, self.config.READ_TIMEOUT)
                )
                
                self.last_request_time = time.time()
                self.request_count += 1
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code == 200:
                    try:
                        data = response.json()
                        if data.get('code') == 200 and 'data' in data:
                            self.success_count += 1
                            if attempt > 0:
                                logger.info(f"APIè¯·æ±‚æˆåŠŸ (é‡è¯• {attempt} æ¬¡å)")
                            return data
                        else:
                            error_msg = data.get('msg', 'æœªçŸ¥é”™è¯¯')
                            logger.warning(f"APIè¿”å›é”™è¯¯: {error_msg}")
                            if attempt < self.config.MAX_RETRIES - 1:
                                logger.info(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                                time.sleep(self.config.RETRY_DELAY)
                                continue
                            return None
                    except json.JSONDecodeError as e:
                        logger.error(f"JSONè§£æå¤±è´¥: {e}")
                        if attempt < self.config.MAX_RETRIES - 1:
                            logger.info(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                            time.sleep(self.config.RETRY_DELAY)
                            continue
                        return None
                else:
                    logger.warning(f"HTTPè¯·æ±‚å¤±è´¥: {response.status_code} - {response.reason}")
                    if attempt < self.config.MAX_RETRIES - 1:
                        logger.info(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                        time.sleep(self.config.RETRY_DELAY)
                        continue
                    return None
                    
            except requests.exceptions.Timeout:
                logger.warning(f"è¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.config.MAX_RETRIES})")
                if attempt < self.config.MAX_RETRIES - 1:
                    logger.info(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    continue
                return None
            except requests.exceptions.ConnectionError:
                logger.warning(f"è¿æ¥é”™è¯¯ (å°è¯• {attempt + 1}/{self.config.MAX_RETRIES})")
                if attempt < self.config.MAX_RETRIES - 1:
                    logger.info(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    continue
                return None
            except requests.exceptions.RequestException as e:
                logger.warning(f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e} (å°è¯• {attempt + 1}/{self.config.MAX_RETRIES})")
                if attempt < self.config.MAX_RETRIES - 1:
                    logger.info(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    continue
                return None
            except Exception as e:
                logger.error(f"æœªçŸ¥é”™è¯¯: {e} (å°è¯• {attempt + 1}/{self.config.MAX_RETRIES})")
                if attempt < self.config.MAX_RETRIES - 1:
                    logger.info(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    continue
                return None
        
        self.error_count += 1
        logger.error("æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œæ”¾å¼ƒè¯·æ±‚")
        return None
    
    def fetch_latest_data(self, limit: int = 1) -> Optional[Dict[str, Any]]:
        """
        è·å–æœ€æ–°æ•°æ®
        
        Args:
            limit: é™åˆ¶è¿”å›æ¡æ•°
            
        Returns:
            APIå“åº”æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # æ„å»ºè¯·æ±‚ä½“
            end_time = datetime.now()
            begin_time = end_time - timedelta(days=7)  # æŸ¥è¯¢æœ€è¿‘7å¤©çš„æ•°æ®
            
            payload = {
                "tbmId": self.config.TBM_ID,
                "beginTime": begin_time.strftime("%Y-%m-%d %H:%M:%S"),
                "endTime": end_time.strftime("%Y-%m-%d %H:%M:%S"),
                "limit": limit
            }
            
            return self._make_request(payload)
            
        except Exception as e:
            logger.error(f"è·å–æœ€æ–°æ•°æ®å¤±è´¥: {e}")
            return None
    
    def fetch_data_by_time_range(self, begin_time: str, end_time: str, limit: Optional[int] = None) -> Optional[Dict[str, Any]]:
        """
        æŒ‰æ—¶é—´èŒƒå›´è·å–æ•°æ®
        
        Args:
            begin_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            limit: é™åˆ¶è¿”å›æ¡æ•°
            
        Returns:
            APIå“åº”æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            payload = {
                "tbmId": self.config.TBM_ID,
                "beginTime": begin_time,
                "endTime": end_time
            }
            
            if limit:
                payload["limit"] = limit
            
            return self._make_request(payload)
            
        except Exception as e:
            logger.error(f"æŒ‰æ—¶é—´èŒƒå›´è·å–æ•°æ®å¤±è´¥: {e}")
            return None
    
    def parse_data_record(self, record: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        è§£æå•æ¡æ•°æ®è®°å½•
        
        Args:
            record: APIè¿”å›çš„å•æ¡æ•°æ®è®°å½•
            
        Returns:
            è§£æåçš„æ•°æ®å­—å…¸
        """
        try:
            # è§£æJSONæ•°æ®å­—æ®µ
            data_json = json.loads(record.get('data', '{}'))
            
            # åˆ›å»ºè§£æç»“æœ
            parsed_data = {
                'id': record.get('id'),
                'tbm_id': record.get('tbmId'),
                'create_time': record.get('createTime'),
                'origin_time': record.get('originTime'),
                'my_time': record.get('myTime'),
                'raw_data': data_json
            }
            
            return parsed_data
            
        except Exception as e:
            logger.error(f"æ•°æ®è®°å½•è§£æå¤±è´¥: {e}")
            return None
    
    def extract_feature_values(self, parsed_data: Dict[str, Any]) -> np.ndarray:
        """
        æå–31ä¸ªç‰¹å¾å€¼
        
        Args:
            parsed_data: è§£æåçš„æ•°æ®
            
        Returns:
            31ä¸ªç‰¹å¾å€¼æ•°ç»„
        """
        try:
            feature_values = np.full(31, None)
            raw_data = parsed_data.get('raw_data', {})
            
            for i, (feature_name, transmission_name) in enumerate(self.config.FEATURE_MAPPING.items()):
                if transmission_name in raw_data:
                    value = raw_data[transmission_name]
                    if value is not None and value != '':
                        try:
                            feature_values[i] = float(value)
                        except (ValueError, TypeError):
                            logger.warning(f"ç‰¹å¾ {i+1} ({feature_name}) å€¼è½¬æ¢å¤±è´¥: {value}")
                            feature_values[i] = None
                    else:
                        feature_values[i] = None
                else:
                    feature_values[i] = None
            
            return feature_values
            
        except Exception as e:
            logger.error(f"ç‰¹å¾å€¼æå–å¤±è´¥: {e}")
            return np.full(31, None)
    
    def get_latest_features(self) -> np.ndarray:
        """
        è·å–æœ€æ–°çš„31ä¸ªç‰¹å¾æ•°æ® - å¢å¼ºç‰ˆæœ¬
        
        Returns:
            31ä¸ªç‰¹å¾å€¼æ•°ç»„ï¼Œç¼ºå¤±å€¼ç”¨Noneè¡¨ç¤º
        """
        try:
            # è·å–æœ€æ–°æ•°æ®
            api_response = self.fetch_latest_data(limit=1)
            
            if not api_response or not api_response.get('data'):
                logger.warning("æœªè·å–åˆ°APIæ•°æ®")
                return np.full(31, None)
            
            # è·å–æœ€æ–°è®°å½•
            records = api_response['data']
            if not records:
                logger.warning("APIè¿”å›ç©ºæ•°æ®")
                return np.full(31, None)
            
            # é€‰æ‹©æœ€æ–°çš„è®°å½•ï¼ˆæŒ‰IDæ’åºï¼Œå–æœ€å¤§çš„ï¼‰
            latest_record = max(records, key=lambda x: x.get('id', 0))
            
            # è§£ææ•°æ®
            parsed_data = self.parse_data_record(latest_record)
            
            if not parsed_data:
                logger.error("æ•°æ®è§£æå¤±è´¥")
                return np.full(31, None)
            
            # æå–ç‰¹å¾å€¼
            feature_values = self.extract_feature_values(parsed_data)
            
            # ç»Ÿè®¡æ•°æ®å®Œæ•´æ€§
            valid_count = np.sum(feature_values != None)
            logger.info(f"è·å–åˆ° {valid_count}/31 ä¸ªæœ‰æ•ˆç‰¹å¾å€¼ (è®°å½•ID: {latest_record.get('id', 'N/A')})")
            
            if valid_count == 31:
                logger.info("æ‰€æœ‰31ä¸ªç‰¹å¾éƒ½æˆåŠŸè·å–åˆ°æ•°æ®ï¼")
            elif valid_count > 0:
                logger.warning(f"æœ‰ {31-valid_count} ä¸ªç‰¹å¾æ•°æ®ç¼ºå¤±")
            
            return feature_values
            
        except Exception as e:
            logger.error(f"è·å–æœ€æ–°ç‰¹å¾æ•°æ®å¤±è´¥: {e}")
            return np.full(31, None)
    
    def get_historical_data(self, minutes_back: int = 5) -> List[Dict[str, Any]]:
        """
        è·å–å†å²æ•°æ®ç”¨äºåˆå§‹åŒ–ç¼“å†²åŒº
        
        Args:
            minutes_back: è·å–å¤šå°‘åˆ†é’Ÿå‰çš„æ•°æ®
            
        Returns:
            åŒ…å«å†å²æ•°æ®è®°å½•çš„åˆ—è¡¨
        """
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_time = datetime.now()
            start_time = end_time - timedelta(minutes=minutes_back)
            
            # æ ¼å¼åŒ–æ—¶é—´å­—ç¬¦ä¸²
            start_time_str = start_time.strftime("%Y-%m-%d %H:%M:%S")
            end_time_str = end_time.strftime("%Y-%m-%d %H:%M:%S")
            
            logger.info(f"è·å–å†å²æ•°æ®: {start_time_str} åˆ° {end_time_str}")
            
            # è·å–å†å²æ•°æ®
            api_response = self.fetch_data_by_time_range(
                begin_time=start_time_str,
                end_time=end_time_str,
                limit=minutes_back
            )
            
            if not api_response or not api_response.get('data'):
                logger.warning("æœªè·å–åˆ°å†å²æ•°æ®")
                return []
            
            records = api_response['data']
            logger.info(f"è·å–åˆ° {len(records)} æ¡å†å²è®°å½•")
            
            # è§£æå†å²æ•°æ®
            historical_data = []
            for i, record in enumerate(records):
                parsed_data = self.parse_data_record(record)
                if parsed_data:
                    feature_values = self.extract_feature_values(parsed_data)
                    valid_count = np.sum(feature_values != None)
                    
                    historical_data.append({
                        'features': feature_values,
                        'timestamp': parsed_data.get('create_time'),
                        'record_id': parsed_data.get('id'),
                        'valid_count': valid_count
                    })
                    
                    logger.debug(f"è®°å½• {i+1}: ID={parsed_data.get('id')}, æœ‰æ•ˆç‰¹å¾={valid_count}/31")
            
            # æŒ‰æ—¶é—´æ’åºï¼Œç¡®ä¿é¡ºåºæ­£ç¡®
            historical_data.sort(key=lambda x: x['record_id'])
            
            logger.info(f"æˆåŠŸè§£æ {len(historical_data)} æ¡å†å²è®°å½•")
            return historical_data
            
        except Exception as e:
            logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {e}")
            return []
    
    def test_connection(self) -> bool:
        """
        æµ‹è¯•APIè¿æ¥
        
        Returns:
            è¿æ¥æˆåŠŸè¿”å›True
        """
        try:
            logger.info("æµ‹è¯•APIè¿æ¥...")
            
            api_response = self.fetch_latest_data(limit=1)
            
            if api_response and api_response.get('data'):
                logger.info("APIè¿æ¥æµ‹è¯•æˆåŠŸ")
                return True
            else:
                logger.warning("APIè¿æ¥æµ‹è¯•å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"APIè¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
            return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–APIå®¢æˆ·ç«¯ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        success_rate = (self.success_count / self.request_count * 100) if self.request_count > 0 else 0
        
        return {
            'total_requests': self.request_count,
            'successful_requests': self.success_count,
            'failed_requests': self.error_count,
            'success_rate': f"{success_rate:.2f}%",
            'last_request_time': self.last_request_time
        }
    
    def reset_statistics(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.request_count = 0
        self.success_count = 0
        self.error_count = 0
        logger.info("ç»Ÿè®¡ä¿¡æ¯å·²é‡ç½®")
    
    def close(self):
        """å…³é—­å®¢æˆ·ç«¯ï¼Œæ¸…ç†èµ„æº"""
        try:
            self.session.close()
            logger.info("APIå®¢æˆ·ç«¯å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­APIå®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")

# =============================================================================
# ç¨‹åºå…¥å£
# =============================================================================
if __name__ == "__main__":
    # æµ‹è¯•APIå®¢æˆ·ç«¯
    client = TBMAPIClientRobust()
    
    try:
        # æµ‹è¯•è¿æ¥
        if client.test_connection():
            print("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ")
            
            # è·å–æœ€æ–°æ•°æ®
            features = client.get_latest_features()
            print(f"ğŸ“Š è·å–åˆ° {np.sum(features != None)}/31 ä¸ªæœ‰æ•ˆç‰¹å¾")
            
            # è·å–å†å²æ•°æ®
            historical = client.get_historical_data(minutes_back=5)
            print(f"ğŸ“… è·å–åˆ° {len(historical)} æ¡å†å²è®°å½•")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = client.get_statistics()
            print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯: {stats}")
        else:
            print("âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥")
    
    finally:
        client.close()
